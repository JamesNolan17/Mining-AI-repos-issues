{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "issue_db = pd.read_csv('issueDB.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def clean_text(issue_content):\n",
    "    if pd.isna(issue_content): return 'None'\n",
    "    issue_content = re.sub(r'\\n', ' ', issue_content)\n",
    "    issue_content = re.sub(r'\\t', ' ', issue_content)\n",
    "    issue_content = re.sub(r'\\r', ' ', issue_content)\n",
    "    # Remove code block ``` xxx ```\n",
    "    issue_content = re.sub(r'```.*?```', ' ', issue_content, flags=re.DOTALL)\n",
    "    # Remove hyperlink [xxx](xxx)\n",
    "    issue_content = re.sub(r'\\[.*?\\]\\(.*?\\)', ' ', issue_content)\n",
    "    # Remove hyperlink ![xxx](xxx)\n",
    "    issue_content = re.sub(r'\\!\\[.*?\\]\\(.*?\\)', ' ', issue_content)\n",
    "    # Remove URL http://xxx\n",
    "    issue_content = re.sub(r'http\\S+', ' ', issue_content)\n",
    "    # Remove XML tag <xxx>\n",
    "    issue_content = re.sub(r'<.*?>', ' ', issue_content)\n",
    "    if re.sub(r' ', '', issue_content) == \"\": return 'None'\n",
    "    return issue_content"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4953\n",
      "4953\n"
     ]
    }
   ],
   "source": [
    "up = 20000 # Contain\n",
    "limit = 20000 # Not contain\n",
    "issue_title = issue_db['Title'][up:].copy()\n",
    "issue_body = issue_db['Body'][up:].copy()\n",
    "assert len(issue_title) == len(issue_body)\n",
    "for i in range(up, up + len(issue_title)):\n",
    "    issue_title[i] = clean_text(issue_title[i])\n",
    "    issue_body[i] = clean_text(issue_body[i])\n",
    "print(len(issue_body))\n",
    "issue_title.to_csv(f'/Users/home/Documents/PyCharm/Senti4SD/ClassificationTask/title{up}-.csv', header=False, index=False)\n",
    "issue_body.to_csv(f'/Users/home/Documents/PyCharm/Senti4SD/ClassificationTask/body{up}-.csv', header=False, index=False)\n",
    "test = pd.read_csv(f'/Users/home/Documents/PyCharm/Senti4SD/ClassificationTask/body{up}-.csv', header=None)\n",
    "print(len(test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4953\n",
      "       Row Predicted\n",
      "7        0  positive\n",
      "2        1   neutral\n",
      "15       2  negative\n",
      "0        3   neutral\n",
      "3        4   neutral\n",
      "...    ...       ...\n",
      "4948  4948   neutral\n",
      "4949  4949   neutral\n",
      "4950  4950   neutral\n",
      "4951  4951   neutral\n",
      "4952  4952  positive\n",
      "\n",
      "[4953 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "prediction = pd.read_csv('/Users/home/Desktop/sentiment/body/predictions20000-.csv')\n",
    "print(len(prediction))\n",
    "#delete the 1st letter of the 'Row' column and convert it to int\n",
    "prediction['Row'] = prediction['Row'].str[1:].astype(int)\n",
    "#sort the dataframe by the 'Row' column\n",
    "prediction = prediction.sort_values(by=['Row'])\n",
    "print(prediction)\n",
    "#output the dataframe to a csv file\n",
    "prediction.to_csv('/Users/home/Desktop/sentiment/body/5.csv', index=False, header=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# Concatenate all the csv files 1 2 3 4 5\n",
    "pd.concat([pd.read_csv('/Users/home/Desktop/sentiment/body/1.csv',header=None),\n",
    "           pd.read_csv('/Users/home/Desktop/sentiment/body/2.csv',header=None),\n",
    "           pd.read_csv('/Users/home/Desktop/sentiment/body/3.csv',header=None),\n",
    "           pd.read_csv('/Users/home/Desktop/sentiment/body/4.csv',header=None),\n",
    "           pd.read_csv('/Users/home/Desktop/sentiment/body/5.csv',header=None)]).to_csv('/Users/home/Desktop/sentiment/body/predictions-body.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24953\n",
      "24953\n",
      "              1\n",
      "0      negative\n",
      "1       neutral\n",
      "2      positive\n",
      "3       neutral\n",
      "4      negative\n",
      "...         ...\n",
      "24948   neutral\n",
      "24949   neutral\n",
      "24950   neutral\n",
      "24951   neutral\n",
      "24952  positive\n",
      "\n",
      "[24953 rows x 1 columns]\n",
      "                                                   Title            Name_Repo  \\\n",
      "24948  Cool work. Do you plan to support large games,...  deepmind/open_spiel   \n",
      "24949                    Infinite loop configuring CMake  deepmind/open_spiel   \n",
      "24950  add_subdirectory given source \"abseil-cpp\" whi...  deepmind/open_spiel   \n",
      "24951                     Failed to invoke `nproc` alias  deepmind/open_spiel   \n",
      "24952                              Public states support  deepmind/open_spiel   \n",
      "\n",
      "        State Assignees  Proposed_By Closed_By         Date_Created  \\\n",
      "24948  closed       NaN  lihuiknight   lanctot  2019-08-28 06:23:02   \n",
      "24949  closed       NaN    bradhowes   lanctot  2019-08-27 16:53:47   \n",
      "24950  closed       NaN    bradhowes   lanctot  2019-08-27 15:52:01   \n",
      "24951  closed       NaN    bradhowes   lanctot  2019-08-27 15:39:54   \n",
      "24952  closed       NaN  michalsustr   lanctot  2019-08-27 14:24:08   \n",
      "\n",
      "               Date_Closed  Num_Comment           Label_Issue  Identity_Repo  \\\n",
      "24948  2019-08-29 21:10:45          8.0                   NaN            5.0   \n",
      "24949  2019-08-28 23:32:51          5.0                   NaN            4.0   \n",
      "24950  2019-08-28 23:25:36         16.0                   NaN            3.0   \n",
      "24951  2019-08-28 01:12:34          1.0                   NaN            2.0   \n",
      "24952  2019-10-17 03:15:03          7.0  contribution welcome            1.0   \n",
      "\n",
      "       Identity_Global                                               Body  \\\n",
      "24948      486182332.0                                                FYI   \n",
      "24949      485923173.0  I'm getting into an infinite loop when running...   \n",
      "24950      485893616.0  Running (patched -- see #2) `./open_spiel/scri...   \n",
      "24951      485887000.0  ```\\r\\n(venv) howes% ./open_spiel/scripts/buil...   \n",
      "24952      485843259.0  I've looked over the code and the arxiv paper ...   \n",
      "\n",
      "      Sentiment_Title Sentiment_Body  \n",
      "24948        positive        neutral  \n",
      "24949         neutral        neutral  \n",
      "24950         neutral        neutral  \n",
      "24951         neutral        neutral  \n",
      "24952        positive       positive  \n"
     ]
    }
   ],
   "source": [
    "all_prediction = pd.read_csv('/Users/home/Desktop/sentiment/body/predictions-body.csv')\n",
    "print(len(all_prediction))\n",
    "print(len(issue_db))\n",
    "assert len(all_prediction) == len(issue_db)\n",
    "# delete the 1st column\n",
    "all_prediction = all_prediction.drop(columns=['0'])\n",
    "print(all_prediction)\n",
    "# append it to the issue_db\n",
    "issue_db['Sentiment_Body'] = all_prediction\n",
    "print(issue_db.tail())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# Output the issue_db to a csv file\n",
    "issue_db = pd.read_csv('issueDB.csv')\n",
    "issue_db['Sentiment_Body'] = all_prediction\n",
    "issue_db.to_csv('issueDB.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287\n"
     ]
    }
   ],
   "source": [
    "# get the max string length of title.txt\n",
    "with open('/Users/home/Desktop/sentiment/title/title0-5000.csv', 'r') as f:\n",
    "    print(max(len(line) for line in f))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# cut every line of dataframe to 300 characters if it is longer than 300\n",
    "limit = 300\n",
    "body_dbs = [pd.read_csv('/Users/home/Documents/PyCharm/Senti4SD/ClassificationTask/body0-.csv', header=None, lineterminator='\\n'),\n",
    "            pd.read_csv('/Users/home/Documents/PyCharm/Senti4SD/ClassificationTask/body5000-.csv', header=None, lineterminator='\\n'),\n",
    "            pd.read_csv('/Users/home/Documents/PyCharm/Senti4SD/ClassificationTask/body10000-.csv', header=None, lineterminator='\\n'),\n",
    "            pd.read_csv('/Users/home/Documents/PyCharm/Senti4SD/ClassificationTask/body15000-.csv', header=None, lineterminator='\\n'),\n",
    "            pd.read_csv('/Users/home/Documents/PyCharm/Senti4SD/ClassificationTask/body20000-.csv', header=None, lineterminator='\\n')]\n",
    "for i in range(len(body_dbs)):\n",
    "    for j in range(len(body_dbs[i])):\n",
    "        if len(body_dbs[i][0][j]) > limit:\n",
    "            body_dbs[i][0][j] = body_dbs[i][0][j][:limit]\n",
    "            body_dbs[i][0][j] = clean_text(body_dbs[i][0][j])\n",
    "    body_dbs[i].to_csv(f'/Users/home/Documents/PyCharm/Senti4SD/ClassificationTask/body{i*5000}-{(i+1)*5000}REVISED.csv', header=False, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                      0\n",
      "4995  Thanks for your great job!  When reading your ...\n",
      "4996  Thank you for your great work! Can you tell me...\n",
      "4997  `OSError: Unable to open file (unable to open ...\n",
      "4998                           貌似你的代码里面没有任何与NTU120有关的内容\n",
      "4999  Hello，how to implement skeleton detection of p...\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('/Users/home/Documents/PyCharm/Senti4SD/ClassificationTask/body0-.csv', header=None)\n",
    "print(test.tail())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}